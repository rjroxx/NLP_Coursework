{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TopicModelling.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNryk7JjXU1QtqJQKE+hOC2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rjroxx/NLP_Coursework/blob/master/TopicModelling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loGbk06wqhE7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import zipfile\n",
        "import nltk\n",
        "from sklearn.decomposition import NMF,LatentDirichletAllocation \n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAHvBJ-3KZrn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "92963de2-dcdb-485a-fcd4-8fe4f9f1a91d"
      },
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "stw = set(stopwords.words('english'))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f26AQ8XiKFV5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "725a5ce2-2749-43c6-f049-04fd594dc4f1"
      },
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp /content/kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!ls ~/.kaggle"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGOgvo2aKI6q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "77f2b9ac-a4b4-4786-da08-3f09e34b7897"
      },
      "source": [
        "!kaggle datasets download -d hj5992/nlp-topic-modelling"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nlp-topic-modelling.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9nx54QaKQnm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9f889aeb-e2fc-4130-9bdb-9e67f112ecf3"
      },
      "source": [
        "datafolder = zipfile.ZipFile('/content/nlp-topic-modelling.zip')\n",
        "datafolder.filelist"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<ZipInfo filename='Reviews.csv' compress_type=deflate file_size=300904694 compress_size=120062195>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqk1rSFHKXg8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(datafolder.open('Reviews.csv'),header=0)\n",
        "df=df.head(500)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rwacbfn-Ke9O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def word_preprocessor(text):\n",
        "  text=re.sub('[^a-zA-Z]', \" \", str(text))\n",
        "  text=text.lower()\n",
        "  text_tokens=word_tokenize(text)\n",
        "  text_tokens_no_sw=[w for w in text_tokens if not w in stw]\n",
        "  text=TreebankWordDetokenizer().detokenize(text_tokens_no_sw)\n",
        "  return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VijfHkcTMAhO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['cleaned_text']=df['Text'].apply(word_preprocessor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtrzybhFN3kz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_rqabAXMbLM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "d929a7de-62c8-4420-9374-690a7c40a903"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Score</th>\n",
              "      <th>Time</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "      <th>cleaned_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>B001E4KFG0</td>\n",
              "      <td>A3SGXH7AUHU8GW</td>\n",
              "      <td>delmartian</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1303862400</td>\n",
              "      <td>Good Quality Dog Food</td>\n",
              "      <td>I have bought several of the Vitality canned d...</td>\n",
              "      <td>bought several vitality canned dog food produc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>B00813GRG4</td>\n",
              "      <td>A1D87F6ZCVE5NK</td>\n",
              "      <td>dll pa</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1346976000</td>\n",
              "      <td>Not as Advertised</td>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
              "      <td>product arrived labeled jumbo salted peanuts p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>B000LQOCH0</td>\n",
              "      <td>ABXLMWJIXXAIN</td>\n",
              "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1219017600</td>\n",
              "      <td>\"Delight\" says it all</td>\n",
              "      <td>This is a confection that has been around a fe...</td>\n",
              "      <td>confection around centuries light pillowy citr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>B000UA0QIQ</td>\n",
              "      <td>A395BORC6FGVXV</td>\n",
              "      <td>Karl</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1307923200</td>\n",
              "      <td>Cough Medicine</td>\n",
              "      <td>If you are looking for the secret ingredient i...</td>\n",
              "      <td>looking secret ingredient robitussin believe f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>B006K2ZZ7K</td>\n",
              "      <td>A1UQRSCLF8GW1T</td>\n",
              "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1350777600</td>\n",
              "      <td>Great taffy</td>\n",
              "      <td>Great taffy at a great price.  There was a wid...</td>\n",
              "      <td>great taffy great price wide assortment yummy ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id  ...                                       cleaned_text\n",
              "0   1  ...  bought several vitality canned dog food produc...\n",
              "1   2  ...  product arrived labeled jumbo salted peanuts p...\n",
              "2   3  ...  confection around centuries light pillowy citr...\n",
              "3   4  ...  looking secret ingredient robitussin believe f...\n",
              "4   5  ...  great taffy great price wide assortment yummy ...\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7yXqAYbMrfy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.drop(['Text'],1,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75O9rUPlMtk6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf_idf=TfidfVectorizer()\n",
        "score=tf_idf.fit_transform(df['cleaned_text'])\n",
        "dense=score.todense()\n",
        "dense1=dense.tolist()\n",
        "col_names=tf_idf.get_feature_names()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkDApTfeNLFz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame(dense1,columns = col_names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OME7NTK4M6j_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "b94db1df-1dc8-4d24-fadf-455c50596d91"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>abby</th>\n",
              "      <th>abdominal</th>\n",
              "      <th>able</th>\n",
              "      <th>absence</th>\n",
              "      <th>absolute</th>\n",
              "      <th>absolutely</th>\n",
              "      <th>absorbs</th>\n",
              "      <th>abt</th>\n",
              "      <th>acai</th>\n",
              "      <th>accept</th>\n",
              "      <th>accompaniment</th>\n",
              "      <th>according</th>\n",
              "      <th>account</th>\n",
              "      <th>accumulated</th>\n",
              "      <th>acid</th>\n",
              "      <th>across</th>\n",
              "      <th>activate</th>\n",
              "      <th>active</th>\n",
              "      <th>activity</th>\n",
              "      <th>acts</th>\n",
              "      <th>actual</th>\n",
              "      <th>actually</th>\n",
              "      <th>ad</th>\n",
              "      <th>add</th>\n",
              "      <th>added</th>\n",
              "      <th>addict</th>\n",
              "      <th>addicted</th>\n",
              "      <th>addicting</th>\n",
              "      <th>addiction</th>\n",
              "      <th>addictive</th>\n",
              "      <th>addicts</th>\n",
              "      <th>adding</th>\n",
              "      <th>addition</th>\n",
              "      <th>additionally</th>\n",
              "      <th>additives</th>\n",
              "      <th>addled</th>\n",
              "      <th>adds</th>\n",
              "      <th>adjustments</th>\n",
              "      <th>admit</th>\n",
              "      <th>admittedly</th>\n",
              "      <th>...</th>\n",
              "      <th>wrap</th>\n",
              "      <th>wrapped</th>\n",
              "      <th>write</th>\n",
              "      <th>writing</th>\n",
              "      <th>wrong</th>\n",
              "      <th>wrote</th>\n",
              "      <th>wu</th>\n",
              "      <th>wuss</th>\n",
              "      <th>www</th>\n",
              "      <th>xdzik</th>\n",
              "      <th>xi</th>\n",
              "      <th>ya</th>\n",
              "      <th>yawning</th>\n",
              "      <th>yay</th>\n",
              "      <th>yeah</th>\n",
              "      <th>year</th>\n",
              "      <th>years</th>\n",
              "      <th>yelling</th>\n",
              "      <th>yerba</th>\n",
              "      <th>yes</th>\n",
              "      <th>yet</th>\n",
              "      <th>yi</th>\n",
              "      <th>yike</th>\n",
              "      <th>yoga</th>\n",
              "      <th>yogurt</th>\n",
              "      <th>york</th>\n",
              "      <th>youll</th>\n",
              "      <th>young</th>\n",
              "      <th>younger</th>\n",
              "      <th>youngest</th>\n",
              "      <th>yrs</th>\n",
              "      <th>yucky</th>\n",
              "      <th>yum</th>\n",
              "      <th>yummy</th>\n",
              "      <th>zack</th>\n",
              "      <th>zen</th>\n",
              "      <th>zero</th>\n",
              "      <th>zest</th>\n",
              "      <th>zing</th>\n",
              "      <th>zip</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.163773</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.122363</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.274493</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.209934</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 3747 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   abby  abdominal  able  absence  absolute  ...  zen  zero  zest  zing  zip\n",
              "0   0.0        0.0   0.0      0.0       0.0  ...  0.0   0.0   0.0   0.0  0.0\n",
              "1   0.0        0.0   0.0      0.0       0.0  ...  0.0   0.0   0.0   0.0  0.0\n",
              "2   0.0        0.0   0.0      0.0       0.0  ...  0.0   0.0   0.0   0.0  0.0\n",
              "3   0.0        0.0   0.0      0.0       0.0  ...  0.0   0.0   0.0   0.0  0.0\n",
              "4   0.0        0.0   0.0      0.0       0.0  ...  0.0   0.0   0.0   0.0  0.0\n",
              "\n",
              "[5 rows x 3747 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNUaKTISNSbN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nmf=NMF(10,random_state=42,alpha=0.1,l1_ratio=0.5,init='nndsvd')\n",
        "arr=nmf.fit_transform(df)\n",
        "comps=nmf.components_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OD_LQPpmNXwI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "2aed5fd0-91a0-4bbf-b1b8-65f7ef443cd8"
      },
      "source": [
        "comps"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.01061965, ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       ...,\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slv-szhFNc6m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lda=LatentDirichletAllocation(n_components=10)\n",
        "model1=lda.fit_transform(df)\n",
        "comps1=lda.components_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIoG59gDNed7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_topics(model, count_vectorizer, n_top_words):\n",
        "    words = count_vectorizer.get_feature_names()\n",
        "    for topic_idx, topic in enumerate(model.components_):\n",
        "        print(\"\\nTopic #%d:\" % topic_idx)\n",
        "        print(\" \".join([words[i]\n",
        "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSUAECWsNkMG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "dd87e241-2068-44de-c1ff-650f693c7231"
      },
      "source": [
        "print_topics(lda,tf_idf,100)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Topic #0:\n",
            "cat cats food delivery however weight dogs products problems still love back old even felidae company candy past fast half flour home aisle price lunch get desserts advertised product store refund trouble mine happy three watchers reputation right less craving impossible health habit started heart packaging black expecting terms apple bound unable winter wife mostly individual retail savings wheatgrass sprouting rye rotate cut create older hunting melted animals fairly throw years issued thawed accept parents around must grass life reasonable berries stores weather filled let anyone locally helpful draw delivered fyi impression awesome dishwasher washed suggests website beans finding purchased\n",
            "\n",
            "Topic #1:\n",
            "like food one allergies good try love ginger tried br found eating best shipping flavor pancakes taste great fresh friends spots vinegar better add day cats oatmeal perfect bought worth soft really dog loved husband regularly eat juice coffee salt used without family time cake works chamomile easy cinnamon tea brands eggs since australian stay money prescription banana oreo available within people use must son size teeth hot frozen oil buy zip shots stuff bread personally come clean flavored soup sweet quaker happen bit serving seem keep organic quality heads new foods lunches variety coffees mushy curb moist told crazy\n",
            "\n",
            "Topic #2:\n",
            "dog great good deal ever delivery got teas best ahmad one asparagus tea looking taffy love try super tasted size toy flavor know prevents ones eat price brand always small disappointed pieces also purchased jello christmas larger pricey worth quality yummy shared purchase buying stuff much lover gift believe tuna ketchup bag enjoyed would ganocafe table described clean rolls tootsie six severs similar middle twizzler soda equals little enough pickled happy shipping per goodness definitely broken without occassions handful jam eating eaten compare unit expensive easy every crisps savory vanilla superb smooth taken ride br years liked expect bright healthy\n",
            "\n",
            "Topic #3:\n",
            "br hot like love chicken product little flavor never good sauce really much taste better chips mix one food way flavors cook brand ketchup add buy might makes great best bought enough spicy calories nice big local get store milder amazon bottle chocolate noodles stuff water bloody small loved thought price around put found heat home low red find use whole brought broth make time side something cookies size picked try cooked also first well deal oatmeal candy ingredients case eaten sugar half typical carried know chewy stores think unique soup labeled mixer sure wonderful grocery expensive life quite bit\n",
            "\n",
            "Topic #4:\n",
            "br buy sugar bad price great get good creamers stuff watch love flavors recommend fine anywhere used cheaper go satisfying italian compared would taste much international delight definitely take absolutely burning italy mushrooms even crisps box oaker differce purchase raw walmart wash problem searching eat years wise back purchased bbq aim pickle pleased away single supposed cream taffy bought assortment mushy oh giant recipients canes puffs chouquettes really bodied target prices fancy chewy cheap toss else crop crackers using thought gold oats hooked kept bake pearls whatever afterwards keep bacause ording stars buying ages add breakfast cheese awful ice think\n",
            "\n",
            "Topic #5:\n",
            "food strawberry good product cancelled six twizzlers br pounds loves india shipping dry lb loved year problem love ages marinade ginger soft sauce around usual great idea bears tarts granted exactly tastes placed dogs cats getting daughter meat ever pretty everyone really frozen pork week time fresh candy cruise jorge reacts try know pleasure guilty frequently party back consistency bought one positive use would pastry brother like asian dishes interested stuff stuck sweet expiration pods peanuts uti old without made mesh hardly stronger date machine latte gummi rings recommend son taste start another spring well enhanced definately decided sick puppy\n",
            "\n",
            "Topic #6:\n",
            "chips br flavor bag tea great coffee kettle amazon sugar love buy good taste delicious price would one like product favorite use bags salt way could find much time best brand many better potato fresh green go get enjoy mix free really recommend shipping cup vinegar order chocolate chip big flavors eat thanks ever well right highly crunch hard wonderful used almost even drink open amount oz drinking mint flavored make fast strong wish little bitter less lemon bit buying never store made local eating salty white box tried crunchy found need another excellent mountain also regular enough put sure\n",
            "\n",
            "Topic #7:\n",
            "br like sugar one taste good chips product mccann oatmeal flavor love great best pack ordering amazon get really instant store better spicy eat hot bags use variety coffee regular buy box still per food grocery potato bad cinnamon brown quality find ordered tried think husband little much excellent maple even favorite thing ramen tasty price take brands ounce meal salt perfect apples kettle far many also year bought sure enough make well two lot anymore look bit last local say unfortunately others probably chip tastes loves free blend almost packs order jalapeno save likes stuff com tea easy flavors\n",
            "\n",
            "Topic #8:\n",
            "arrived great order breath used mints extremely yet box hard convenient often food wedding salmon product olives list chips came stale powder could regular loaded size ordered old melt throw loves dry taste time awesome weavers looking much night worked seller espresso case kirkland quick however days door south dirty pocket covered broken sometimes sure weather cats resemble cutting scratching take packaging water always lock spicy tasty couscous cashews purse tasted strong finish getting zip ham nuts father dad tastes altoids container bags msg realize wk beagle beats rio wonderful boil like im substantial met forget nothing granules stuffed anchovy\n",
            "\n",
            "Topic #9:\n",
            "energy natural dog food good taste like healthy great balance br tried sweet steaz get works ingredients try different started results shot organic since keep pretty tea also better make drinks spicy well found version stores dogs chocolate thai drink lamb two herbal day time right going onion foods oil plus grocery rice really friends would favorite looking blend one chips snack sure molasses little gives sour bulk even high diet times back know something eaten months mg itching helps tasting got order go three want easy amazon licorice bit help every light cut tastes used love online candy type\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyz6b_EcNlqT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "89c0c014-cb44-4644-d4db-9dda6df6fc74"
      },
      "source": [
        "print_topics(nmf,tf_idf,100)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Topic #0:\n",
            "good like taste product love great one price get amazon coffee buy flavor really would use much better time bags store way order little try bag well eat box easy less go make mix stuff used tastes even chocolate could fresh find shipping bit grocery bad bought flavors still stores two add also local sure per tried free enough healthy found got cheaper think whole hard big size water candy brand many tasty thought ordering first perfect food flavored buying always every pretty take save delicious came products nice expensive online husband sometimes loved eating never fast without half small\n",
            "\n",
            "Topic #1:\n",
            "chips kettle potato flavor vinegar salt bag chip brand love favorite crunch cheddar great onion amount buy spicy crunchy eaten salty cooked really thai right perfect like bags eating never enjoy sweet flavors tangy thick tried greasy taste jalapeno many better perfectly dijon fat sour also oz recommend sea hard amazon honey friends eat amazing know open definitely top bit personally money best sure size brown disappointed enough flavored decided little find list lot rather ones baked way without fairly tasty try loaded tasting might side even vinegary aggressively brands delicious hands every http www gp href deal flavorful highly\n",
            "\n",
            "Topic #2:\n",
            "br sauce teas almost small water product find us pack quality need years amazon much strawberry give ahmad local date plastic flavors oil boxes href gp www http eat thanks like fresh also expiration lunch cons try believe many tired com want care change kind another packaging keurig combination napkin feeling cats thing price pros tuna think box dollars milk make green day mean one earth help makes probably plain superb happy well cup offer staral disappointed variety service grocery year hate per sold every run twizzlers personal problem time followed back half people getting work wash highly none mix\n",
            "\n",
            "Topic #3:\n",
            "food dog balance dogs natural allergies cats cat dry lamb old rice foods itching feed since wet felidae problems year loves started severs eat different eats one pet seems allergic new holistic feeding formula brand tried also last kibble prescription see get vet issues something back digestion right change cause environmental switched limited eating like day puppies wonders mix brown finally put recommended ages soft smells changed well works happy couple ingredients gas find required standard allergy prime found door increased past higher meal shipping select done lot weight scratching bowls know better free russell jack previous loved much uti\n",
            "\n",
            "Topic #4:\n",
            "tea ahmad years drink teas black drinking green sweet one excellent iced herbal day chamomile aroma prepare bodied making eith looseleaf thanks aftertaste lingering favorite quality blend enough mg everyday usually enjoying throughout full recommend coffee afternoons box samovar pound especially past habit white think organic available curb highly know without hot certainly buisiness evenings bodum press amazon breakfast remain hi kind assam health current pot granted south long merchant water taste imperial mornings crisp enjoyed subtle store find souchong lapsang cup superb russian sachets helps grey reviewer mine beautiful tried doctor elsewhere package many exactly mom done area english\n",
            "\n",
            "Topic #5:\n",
            "oatmeal mccann instant variety cinnamon apples pack oats maple brown regular morning count good irish boxes steel better excellent brand convenient sugar cut minutes water time almost flavors tastes meal make thing every bowl microwave though need milk happy apple half cooks plus store minute three prepare breakfast cane best texture like guar seconds mushy sugary likes add quaker gum choice great maybe corn soggy oat hits bariatric post bloat may reccomended eo qw overly syrup become hardy digestible surgery none high instead thick able holds palatable fiber wife nuke top non close folks easily grocery raisins lifesaver abby tastier\n",
            "\n",
            "Topic #6:\n",
            "energy steaz shot shots drink caffeine taste drinks works natural hour day boost guayaki results feel others greatest well drinking looking tried junkie organic work body know found sucralose gives like one husband products effect sure red takes without sensitive yerba splenda terms mate used chemicals ingredients sugar mornings helps hours get feeling putting jitters bottle acai bulls energized said bazi bypass gastric coca tons cola sweeteners beverages also effects surgery give getting favorite almost slightly rain plus continuous heinous shipments artificial provides think allergic nos reassuring wonder fake mg help thing bottles definitely coffee jittery probably avoid improved moderate\n",
            "\n",
            "Topic #7:\n",
            "sugar white raw brown use regular crystals muscavado better much wish place suppose profile maple sweet resealable something recommend also granules melt free turbinado crop baking normal pure still smaller buy cheaper mints glass put seem cheapest minerals contains terrible get great quite delicious diets bulk easy bottom turn called enjoy cereal complaint aroma makes color little affordable week read missing recent plus happy real cinnamon compared delivered watch intake packaged wise wondering really satisfying found price refined finer look set everyday used tin colored spit shame liable producer fine fight fantastic fantastically filling far farms fill fillers filled figured\n",
            "\n",
            "Topic #8:\n",
            "hot spicy sauce salsa noodles ramen might love spots used chicken usually little chilihead flavor kid found enough like bottle scoff billing salsas labeled lives opposite liking heat foods never tequila bother sure broth sweet ingredients since loved victoria eating want bad wrong cornbread really brought kinda scotties tolerablel us tasty hint mouth medium sweetness burns walmart maruchan within makes gone ranchera texas service mix week obviously de picante flavour bummed tastelessly ecstatic cactus blown inclan incredible throat prevalent fan city realize magic trip personal make milder good picked internet realized grab enjoy combo life smell dogs totally unique one\n",
            "\n",
            "Topic #9:\n",
            "best ever delivery fresh one eaten tasted delicious fast addicted deal samovar clean good try anymore excellent great far need live bright say flavor especially prepare could rolls tootsie ketchup love vanilla teas occassions quality special crisps tasting regular wow chocolate tried buy make ones cooking perfect sandwich ginger takes seem chicken pepper whole loves filled film fifteen family fills fifty filling fillers familiar filberts fill fig fall fight figured filets finally finace fats falksalt firms fixed fix fajita five fits fit fish firstly first fire find finish finicky fingers finer finely fine fajitas famous finding fake fiance fields feeding\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HleHy5PaNqEl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
